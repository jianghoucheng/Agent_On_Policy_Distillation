2025-11-26 00:33:14,698 INFO    MainThread:3756337 [wandb_setup.py:_flush():80] Current SDK version is 0.23.0
2025-11-26 00:33:14,698 INFO    MainThread:3756337 [wandb_setup.py:_flush():80] Configure stats pid to 3756337
2025-11-26 00:33:14,698 INFO    MainThread:3756337 [wandb_setup.py:_flush():80] Loading settings from /data0/user10/.config/wandb/settings
2025-11-26 00:33:14,698 INFO    MainThread:3756337 [wandb_setup.py:_flush():80] Loading settings from /data0/user10/Open-AgentRL/wandb/settings
2025-11-26 00:33:14,698 INFO    MainThread:3756337 [wandb_setup.py:_flush():80] Loading settings from environment variables
2025-11-26 00:33:14,698 INFO    MainThread:3756337 [wandb_init.py:setup_run_log_directory():713] Logging user logs to /data0/user10/Open-AgentRL/wandb/run-20251126_003314-3gg1r8jf/logs/debug.log
2025-11-26 00:33:14,698 INFO    MainThread:3756337 [wandb_init.py:setup_run_log_directory():714] Logging internal logs to /data0/user10/Open-AgentRL/wandb/run-20251126_003314-3gg1r8jf/logs/debug-internal.log
2025-11-26 00:33:14,698 INFO    MainThread:3756337 [wandb_init.py:init():840] calling init triggers
2025-11-26 00:33:14,699 INFO    MainThread:3756337 [wandb_init.py:init():845] wandb.init called with sweep_config: {}
config: {'actor_rollout_ref': {'actor': {'_target_': 'verl.workers.config.FSDPActorConfig', 'strategy': 'fsdp', 'ppo_mini_batch_size': 16, 'ppo_micro_batch_size': None, 'ppo_micro_batch_size_per_gpu': None, 'use_dynamic_bsz': True, 'ppo_max_token_len_per_gpu': 18432, 'clip_ratio': 0.2, 'clip_ratio_low': 0.2, 'clip_ratio_high': 0.28, 'policy_loss': {'_target_': 'verl.workers.config.PolicyLossConfig', 'loss_mode': 'vanilla', 'clip_cov_ratio': 0.0002, 'clip_cov_lb': 1.0, 'clip_cov_ub': 5.0, 'kl_cov_ratio': 0.0002, 'ppo_kl_coef': 0.1}, 'clip_ratio_c': 10.0, 'loss_agg_mode': 'token-mean', 'entropy_coeff': 0, 'tis_imp_ratio_cap': -1, 'use_kl_loss': False, 'use_torch_compile': True, 'kl_loss_coef': 0.0, 'kl_loss_type': 'low_var_kl', 'ppo_epochs': 1, 'shuffle': False, 'checkpoint': {'_target_': 'verl.trainer.config.CheckpointConfig', 'save_contents': ['model', 'optimizer', 'extra'], 'load_contents': ['model', 'optimizer', 'extra'], 'async_save': False}, 'optim': {'lr': 1e-06, 'lr_warmup_steps_ratio': 0.0, 'total_training_steps': 1410, 'weight_decay': 0.01, 'lr_warmup_steps': -1, '_target_': 'verl.workers.config.FSDPOptimizerConfig', 'min_lr_ratio': 0.0, 'num_cycles': 0.5, 'warmup_style': 'constant'}, 'use_fused_kernels': False, 'profiler': {'_target_': 'verl.utils.profiler.ProfilerConfig', 'tool': None, 'enable': False, 'all_ranks': False, 'ranks': [], 'save_path': 'outputs/profile', 'tool_config': {'nsys': {'_target_': 'verl.utils.profiler.config.NsightToolConfig', 'discrete': False}, 'npu': {'_target_': 'verl.utils.profiler.config.NPUToolConfig', 'contents': [], 'level': 'level1', 'analysis': True, 'discrete': False}, 'torch': {'_target_': 'verl.utils.profiler.config.TorchProfilerToolConfig', 'step_start': 0, 'step_end': None}, 'torch_memory': {'_target_': 'verl.utils.profiler.config.TorchMemoryToolConfig', 'trace_alloc_max_entries': 100000, 'stack_depth': 32}}}, 'grad_clip': 1.0, 'ulysses_sequence_parallel_size': 8, 'entropy_from_logits_with_chunking': False, 'entropy_checkpointing': False, 'fsdp_config': {'_target_': 'verl.workers.config.FSDPEngineConfig', 'wrap_policy': {'min_num_params': 0}, 'param_offload': True, 'optimizer_offload': True, 'offload_policy': False, 'reshard_after_forward': True, 'fsdp_size': -1, 'forward_prefetch': False}, 'use_remove_padding': True}, 'ref': {'strategy': 'fsdp', 'use_torch_compile': True, 'log_prob_micro_batch_size': None, 'log_prob_micro_batch_size_per_gpu': None, 'log_prob_use_dynamic_bsz': True, 'log_prob_max_token_len_per_gpu': 73728, 'profiler': {'_target_': 'verl.utils.profiler.ProfilerConfig', 'tool': None, 'enable': False, 'all_ranks': False, 'ranks': [], 'save_path': 'outputs/profile', 'tool_config': {'nsys': {'_target_': 'verl.utils.profiler.config.NsightToolConfig', 'discrete': False}, 'npu': {'_target_': 'verl.utils.profiler.config.NPUToolConfig', 'contents': [], 'level': 'level1', 'analysis': True, 'discrete': False}, 'torch': {'_target_': 'verl.utils.profiler.config.TorchProfilerToolConfig', 'step_start': 0, 'step_end': None}, 'torch_memory': {'_target_': 'verl.utils.profiler.config.TorchMemoryToolConfig', 'trace_alloc_max_entries': 100000, 'stack_depth': 32}}}, 'model': None, 'fsdp_config': {'_target_': 'verl.workers.config.FSDPEngineConfig', 'wrap_policy': {'min_num_params': 0}, 'param_offload': False, 'reshard_after_forward': True, 'forward_prefetch': False}, 'ulysses_sequence_parallel_size': 8, 'entropy_from_logits_with_chunking': False, 'entropy_checkpointing': False}, 'rollout': {'_target_': 'verl.workers.config.RolloutConfig', 'name': 'vllm', 'mode': 'async', 'temperature': 1.0, 'top_k': -1, 'top_p': 1, 'prompt_length': 2048, 'response_length': 16384, 'dtype': 'bfloat16', 'gpu_memory_utilization': 0.6, 'ignore_eos': False, 'enforce_eager': False, 'cudagraph_capture_sizes': None, 'free_cache_engine': True, 'tensor_model_parallel_size': 4, 'max_num_batched_tokens': 8192, 'max_model_len': None, 'max_num_seqs': 1024, 'log_prob_micro_batch_size': None, 'log_prob_micro_batch_size_per_gpu': None, 'log_prob_use_dynamic_bsz': True, 'log_prob_max_token_len_per_gpu': 18432, 'disable_log_stats': True, 'do_sample': True, 'n': 16, 'over_sample_rate': 0, 'multi_stage_wake_up': False, 'engine_kwargs': {'vllm': {}, 'sglang': {}}, 'val_kwargs': {'_target_': 'verl.workers.config.SamplingConfig', 'top_k': -1, 'top_p': 0.6, 'temperature': 1.0, 'n': 32, 'do_sample': False}, 'multi_turn': {'_target_': 'verl.workers.config.MultiTurnConfig', 'enable': True, 'max_assistant_turns': 16, 'tool_config_path': 'recipe/demystify/sandbox_fusion_tool_config.yaml', 'max_user_turns': 16, 'max_parallel_calls': 1, 'max_tool_response_length': 256, 'tool_response_truncate_side': 'middle', 'interaction_config_path': None, 'use_inference_chat_template': False, 'tokenization_sanity_check_mode': 'strict', 'format': 'hermes'}, 'calculate_log_probs': False, 'agent': {'_target_': 'verl.workers.config.AgentLoopConfig', 'num_workers': 8, 'agent_loop_config_path': None, 'custom_async_server': {'_target_': 'verl.workers.config.CustomAsyncServerConfig', 'path': None, 'name': None}}, 'update_weights_bucket_megabytes': 512, 'trace': {'_target_': 'verl.workers.config.TraceConfig', 'backend': None, 'token2text': False}, 'skip_rollout': False, 'skip_dump_dir': '/tmp/rollout_dump', 'profiler': {'_target_': 'verl.utils.profiler.ProfilerConfig', 'tool': None, 'enable': False, 'all_ranks': False, 'ranks': [], 'save_path': 'outputs/profile', 'tool_config': {'nsys': {'_target_': 'verl.utils.profiler.config.NsightToolConfig', 'discrete': False}, 'npu': {'_target_': 'verl.utils.profiler.config.NPUToolConfig', 'contents': [], 'level': 'level1', 'analysis': True, 'discrete': False}, 'torch': {'_target_': 'verl.utils.profiler.config.TorchProfilerToolConfig', 'step_start': 0, 'step_end': None}, 'torch_memory': {'_target_': 'verl.utils.profiler.config.TorchMemoryToolConfig', 'trace_alloc_max_entries': 100000, 'stack_depth': 32}}}, 'enable_chunked_prefill': True, 'load_format': 'dummy_dtensor', 'layered_summon': False}, 'hybrid_engine': True, 'nccl_timeout': 600, 'model': {'path': '/data0/user10/Open-AgentRL/checkpoint/Qwen3-4B-RA-SFT', 'custom_chat_template': None, 'use_shm': False, 'external_lib': None, 'override_config': {}, 'enable_gradient_checkpointing': True, 'enable_activation_offload': False, 'use_remove_padding': True, 'lora_rank': 0, 'lora_alpha': 16, 'target_modules': 'all-linear', 'exclude_modules': None, 'use_liger': False, 'use_fused_kernels': False, 'fused_kernel_options': {'impl_backend': 'torch'}, 'trust_remote_code': False}}, 'data': {'tokenizer': None, 'use_shm': False, 'train_files': ['/data0/user10/Open-AgentRL/dataset/Gen-Verse/Open-AgentRL-30K/Open-AgentRL-30K.parquet'], 'val_files': ['/data0/user10/Open-AgentRL/dataset/Gen-Verse/Open-AgentRL-Eval/aime2025/aime_2025_problems.parquet', '/data0/user10/Open-AgentRL/dataset/Gen-Verse/Open-AgentRL-Eval/aime2024/aime_2024_problems.parquet'], 'prompt_key': 'prompt', 'reward_fn_key': 'data_source', 'max_prompt_length': 2048, 'max_response_length': 16384, 'train_batch_size': 64, 'val_batch_size': None, 'return_raw_input_ids': False, 'return_raw_chat': True, 'return_full_prompt': False, 'shuffle': True, 'dataloader_num_workers': 8, 'validation_shuffle': False, 'filter_overlong_prompts': True, 'filter_overlong_prompts_workers': 1, 'truncation': 'error', 'image_key': 'images', 'video_key': 'videos', 'trust_remote_code': False, 'custom_cls': {'path': 'recipe/demystify/reward.py', 'name': 'CustomRLHFDataset'}, 'return_multi_modal_inputs': True, 'sampler': {'class_path': None, 'class_name': None}, 'datagen': {'path': None, 'name': None}, 'apply_chat_template_kwargs': {}}, 'critic': {'_target_': 'verl.workers.config.FSDPCriticConfig', 'rollout_n': 16, 'strategy': 'fsdp', 'enable': None, 'optim': {'lr': 1e-05, 'lr_warmup_steps_ratio': 0.0, 'total_training_steps': 1410, 'weight_decay': 0.01, 'lr_warmup_steps': -1, '_target_': 'verl.workers.config.FSDPOptimizerConfig', 'min_lr_ratio': None, 'warmup_style': 'constant'}, 'model': {'path': '~/models/deepseek-llm-7b-chat', 'tokenizer_path': '/data0/user10/Open-AgentRL/checkpoint/Qwen3-4B-RA-SFT', 'override_config': {}, 'external_lib': None, 'trust_remote_code': False, '_target_': 'verl.workers.config.FSDPCriticModelCfg', 'use_shm': False, 'enable_gradient_checkpointing': True, 'enable_activation_offload': False, 'use_remove_padding': False, 'fsdp_config': {'_target_': 'verl.workers.config.FSDPEngineConfig', 'param_offload': False, 'optimizer_offload': False, 'offload_policy': False, 'reshard_after_forward': True, 'wrap_policy': {'min_num_params': 0}, 'fsdp_size': -1, 'forward_prefetch': False}, 'lora_rank': 0, 'lora_alpha': 16, 'target_modules': 'all-linear'}, 'ppo_mini_batch_size': 16, 'ppo_micro_batch_size': None, 'ppo_micro_batch_size_per_gpu': None, 'use_dynamic_bsz': True, 'ppo_max_token_len_per_gpu': 32768, 'forward_max_token_len_per_gpu': 32768, 'ppo_epochs': 1, 'shuffle': False, 'cliprange_value': 0.5, 'loss_agg_mode': 'token-mean', 'checkpoint': {'_target_': 'verl.trainer.config.CheckpointConfig', 'save_contents': ['model', 'optimizer', 'extra'], 'load_contents': ['model', 'optimizer', 'extra'], 'async_save': False}, 'profiler': {'_target_': 'verl.utils.profiler.ProfilerConfig', 'tool': None, 'enable': False, 'all_ranks': False, 'ranks': [], 'save_path': 'outputs/profile', 'tool_config': {'nsys': {'_target_': 'verl.utils.profiler.config.NsightToolConfig', 'discrete': False}, 'npu': {'_target_': 'verl.utils.profiler.config.NPUToolConfig', 'contents': [], 'level': 'level1', 'analysis': True, 'discrete': False}, 'torch': {'_target_': 'verl.utils.profiler.config.TorchProfilerToolConfig', 'step_start': 0, 'step_end': None}, 'torch_memory': {'_target_': 'verl.utils.profiler.config.TorchMemoryToolConfig', 'trace_alloc_max_entries': 100000, 'stack_depth': 32}}}, 'forward_micro_batch_size': None, 'forward_micro_batch_size_per_gpu': None, 'ulysses_sequence_parallel_size': 1, 'grad_clip': 1.0}, 'reward_model': {'enable': False, 'strategy': 'fsdp', 'model': {'input_tokenizer': '/data0/user10/Open-AgentRL/checkpoint/Qwen3-4B-RA-SFT', 'path': '~/models/FsfairX-LLaMA3-RM-v0.1', 'external_lib': None, 'trust_remote_code': False, 'use_shm': False, 'use_remove_padding': False, 'use_fused_kernels': False, 'fsdp_config': {'_target_': 'verl.workers.config.FSDPEngineConfig', 'wrap_policy': {'min_num_params': 0}, 'param_offload': False, 'reshard_after_forward': True, 'fsdp_size': -1, 'forward_prefetch': False}}, 'micro_batch_size': None, 'micro_batch_size_per_gpu': None, 'max_length': None, 'use_dynamic_bsz': True, 'forward_max_token_len_per_gpu': 32768, 'reward_manager': 'dapo', 'launch_reward_fn_async': False, 'sandbox_fusion': {'url': None, 'max_concurrent': 512, 'memory_limit_mb': 2048}, 'profiler': {'_target_': 'verl.utils.profiler.ProfilerConfig', 'tool': None, 'enable': False, 'all_ranks': False, 'ranks': [], 'save_path': 'outputs/profile', 'tool_config': {'nsys': {'_target_': 'verl.utils.profiler.config.NsightToolConfig', 'discrete': False}, 'npu': {'_target_': 'verl.utils.profiler.config.NPUToolConfig', 'contents': [], 'level': 'level1', 'analysis': True, 'discrete': False}, 'torch': {'_target_': 'verl.utils.profiler.config.TorchProfilerToolConfig', 'step_start': 0, 'step_end': None}, 'torch_memory': {'_target_': 'verl.utils.profiler.config.TorchMemoryToolConfig', 'trace_alloc_max_entries': 100000, 'stack_depth': 32}}}, 'ulysses_sequence_parallel_size': 1, 'reward_kwargs': {'overlong_buffer_cfg': {'enable': True, 'len': 2048, 'penalty_factor': 1.0, 'log': False}, 'max_resp_len': 16384}}, 'custom_reward_function': {'path': 'recipe/demystify/reward.py', 'name': 'compute_score'}, 'algorithm': {'_target_': 'verl.trainer.config.AlgoConfig', 'gamma': 1.0, 'lam': 1.0, 'adv_estimator': 'grpo', 'norm_adv_by_std_in_grpo': True, 'use_kl_in_reward': False, 'kl_penalty': 'kl', 'kl_ctrl': {'_target_': 'verl.trainer.config.KLControlConfig', 'type': 'fixed', 'kl_coef': 0.0, 'horizon': 10000, 'target_kl': 0.1}, 'use_pf_ppo': False, 'pf_ppo': {'reweight_method': 'pow', 'weight_pow': 2.0}}, 'trainer': {'balance_batch': True, 'total_epochs': 3, 'total_training_steps': None, 'project_name': 'demystify-agentic-rl', 'experiment_name': 'GRPO-TCR-Qwen3-4B', 'logger': ['console', 'wandb'], 'log_val_generations': 20, 'rollout_data_dir': None, 'validation_data_dir': None, 'nnodes': 1, 'n_gpus_per_node': 8, 'save_freq': 30, 'esi_redundant_time': 0, 'resume_mode': 'auto', 'resume_from_path': None, 'val_before_train': True, 'val_only': False, 'test_freq': 10, 'critic_warmup': 0, 'default_hdfs_dir': None, 'del_local_ckpt_after_load': False, 'default_local_dir': '/data0/user10/Open-AgentRL/checkpoint/GRPO-TCR-Qwen3-4B', 'max_actor_ckpt_to_keep': None, 'max_critic_ckpt_to_keep': None, 'ray_wait_register_center_timeout': 300, 'device': 'cuda', 'use_legacy_worker_impl': 'auto'}, 'global_profiler': {'_target_': 'verl.utils.profiler.ProfilerConfig', 'tool': None, 'steps': None, 'profile_continuous_steps': False, 'save_path': 'outputs/profile', 'global_tool_config': {'nsys': {'_target_': 'verl.utils.profiler.config.NsightToolConfig', 'discrete': False, 'controller_nsight_options': {'trace': 'cuda,nvtx,cublas,ucx', 'cuda-memory-usage': 'true', 'cuda-graph-trace': 'graph'}, 'worker_nsight_options': {'trace': 'cuda,nvtx,cublas,ucx', 'cuda-memory-usage': 'true', 'cuda-graph-trace': 'graph', 'capture-range': 'cudaProfilerApi', 'capture-range-end': None, 'kill': 'none'}}, 'torch_memory': {'trace_alloc_max_entries': 100000, 'stack_depth': 32, 'context': 'all', 'stacks': 'all', 'kw_args': {}}}}, 'ray_kwargs': {'ray_init': {'num_cpus': None}, 'timeline_json_file': None}, '_wandb': {}}
2025-11-26 00:33:14,699 INFO    MainThread:3756337 [wandb_init.py:init():888] starting backend
2025-11-26 00:33:14,945 INFO    MainThread:3756337 [wandb_init.py:init():891] sending inform_init request
2025-11-26 00:33:14,948 INFO    MainThread:3756337 [wandb_init.py:init():899] backend started and connected
2025-11-26 00:33:14,952 INFO    MainThread:3756337 [wandb_init.py:init():969] updated telemetry
2025-11-26 00:33:14,955 INFO    MainThread:3756337 [wandb_init.py:init():993] communicating run to backend with 90.0 second timeout
2025-11-26 00:33:16,168 INFO    MainThread:3756337 [wandb_init.py:init():1040] starting run threads in backend
2025-11-26 00:33:16,328 INFO    MainThread:3756337 [wandb_run.py:_console_start():2504] atexit reg
2025-11-26 00:33:16,328 INFO    MainThread:3756337 [wandb_run.py:_redirect():2352] redirect: wrap_raw
2025-11-26 00:33:16,328 INFO    MainThread:3756337 [wandb_run.py:_redirect():2421] Wrapping output streams.
2025-11-26 00:33:16,328 INFO    MainThread:3756337 [wandb_run.py:_redirect():2444] Redirects installed.
2025-11-26 00:33:16,329 INFO    MainThread:3756337 [wandb_init.py:init():1080] run started, returning control to user process
2025-11-26 01:11:08,158 INFO    MainThread:3756337 [wandb_run.py:_finish():2270] finishing run 1305345959-ustc/demystify-agentic-rl/3gg1r8jf
2025-11-26 01:11:08,159 INFO    MainThread:3756337 [wandb_run.py:_atexit_cleanup():2469] got exitcode: 0
2025-11-26 01:11:08,159 INFO    MainThread:3756337 [wandb_run.py:_restore():2451] restore
2025-11-26 01:11:08,160 INFO    MainThread:3756337 [wandb_run.py:_restore():2457] restore done
2025-11-26 01:11:10,348 INFO    MainThread:3756337 [wandb_run.py:_footer_sync_info():3853] logging synced files
